README languages/è¯­è¨€:
- [![English](https://img.shields.io/badge/lang-EN-green.svg)](https://github.com/yizhilll/CORGI-PM/READM.md)
- [![ä¸­æ–‡](https://img.shields.io/badge/lang-ä¸­æ–‡-red.svg)](https://github.com/yizhilll/CORGI-PM/README.zh.md)

# ä»‹ç»

CORGI-PMğŸ¶ æ˜¯ä¸€ä¸ªä¸­æ–‡æ€§åˆ«åè§æ¢æµ‹å’Œç¼“è§£è¯­æ–™åº“ï¼ŒåŒ…å«32.9kä¸ªå¥å­ï¼Œé€šè¿‡æŒ‰ç…§ç‰¹å®šçš„ä¸­æ–‡æ€§åˆ«åè§æ³¨é‡Šæ–¹æ¡ˆè¿›è¡Œé«˜è´¨é‡æ ‡æ³¨ã€‚

æˆ‘ä»¬æå‡ºäº†è‡ªåŠ¨æ–‡æœ¬æ€§åˆ«åè§ç¼“è§£ç›¸å…³çš„ä¸‰ä¸ªæŒ‘æˆ˜ï¼šæ¨¡å‹è¢«è¦æ±‚èƒ½å‹¾æ£€æµ‹ã€åˆ†ç±»å’Œç¼“è§£æ–‡æœ¬ä¸­çš„æ€§åˆ«åè§ã€‚

# æ•°æ®ç”¨é€”

æˆ‘ä»¬çš„æ•°æ®é›†å­˜å‚¨åœ¨ .npy äºŒè¿›åˆ¶æ–‡ä»¶ä¸­ï¼Œå¯ä»¥è½»æ¾æ‰“å¼€å¹¶è½¬æˆå…¶ä»–æ ¼å¼ã€‚

## æ ‡æ³¨ã€Œæœ‰åè§ã€çš„è¯­æ–™

æ•°æ®é›†ç»“æ„å¦‚ä¸‹ï¼š

```python
{
    'train':{
        # original corpus
        'ori_sentence': [
            sent_0,
            sent_1,
            ...,
        ], 
        # bias types, stored as one-hot labels
        'bias_labels': [
            [0 1 0],
            [0 1 0],
            [0 1 0],
            ...,
        ],
        # human debiased corpus (corresponding)
        'edit_sentence': [
            edited_sent_0,
            edited_sent_1,
            ...,
        ],
    },
    'valid':{
        ... # similar
    },
    'test':{
        ... # similar
    }
}
```

åŠ è½½è¯­æ–™å’Œæ ‡æ³¨çš„æŒ‡ä»¤ï¼š
```python
>>> import numpy as np

# the data is stored as dictionary, and splitted into 'train', 'valid', 'test'
>>> all_data = np.load('dataset/CORGI-PC_splitted_biased_corpus_v1.npy',allow_pickle=True).item()
>>> print(all_data.keys())
dict_keys(['train', 'valid', 'test'])

# to get the original biased text:
>>> print(all_data['valid']['ori_sentence'][:3])
['é‚£æ—¶å€™ä¸œå±±ä¾ç„¶åœ¨ä½¿ç€çœ¼è‰²ï¼Œå¯ä»–çš„æ–°å¨˜å› ä¸ºæ— æ³•ç†è§£è€Œè„¸ä¸Šå¸ƒæ»¡äº†æ„šè ¢ã€‚äºæ˜¯ä¸œå±±ä¾¿å‡‘è¿‡å»å’¬ç‰™åˆ‡é½¿åœ°è¯´äº†ä¸€å¥ä»€ä¹ˆï¼Œæ€»ç®—æ˜ç™½è¿‡æ¥çš„æ–°å¨˜è„¸ä¸Šå‡ºç°äº†å¹½é»˜çš„å¾®ç¬‘ã€‚éšå³ä¸œå±±å’Œä»–çš„æ–°å¨˜ä¸€èµ·ç«™äº†èµ·æ¥ã€‚ä¸œå±±ç«™èµ·æ¥æ—¶ååˆ†ç²—é²ï¼Œä»–è¸¢å€’äº†æ¤…å­ã€‚æ­£å¦‚æ£®æ—äº‹å…ˆé¢„æ–™çš„ä¸€æ ·ï¼Œä»–ä»¬èµ°è¿›äº†é‚£ä¸ªæˆ¿é—´ã€‚ä½†æ˜¯ä»–ä»¬æ²¡æœ‰å°†é—¨å…³ä¸Šï¼Œæ‰€ä»¥æ£®æ—ä»ç„¶çœ‹åˆ°é‚£å¼ åºŠçš„ä¸€åªè§’ï¼Œä¸è¿‡æ²¡æœ‰çœ‹åˆ°ä»–ä»¬ä¸¤äººï¼Œä»–ä»¬åœ¨åºŠçš„å¦ä¸€ç«¯ã€‚ç„¶åé‚£æ‰‡é—¨å…³ä¸Šäº†ã€‚ä¸ä¹…ä¹‹åï¼Œé‚£é—´å±‹å­é‡Œå‡èµ·äº†ä¸€ç§...'
 'ä¸‹è´±ä¸œè¥¿ï¼Œå¤§çº¦å¥¹çŸ¥é“è‡ªå·±å¤ªä¸è¡Œï¼Œå¿…é¡»æ‰¾ä¸ªæ¯”å¥¹å†ä¸‹è´±çš„ã€‚'
 'èƒ¡æ–‡ç‰ä¸åªç”Ÿçš„é­ä¼Ÿä¿Šç§€ï¼Œè€Œä¸”å·¥ä½œä¸Šæœ‰é­„åŠ›ï¼Œæœ‰åŠæ³•ï¼Œå†™å¾—ä¸€æ‰‹å¥½æ–‡ç« ï¼Œè®²èµ·è¯æ¥åˆå¤´å¤´æ˜¯é“ã€‚']

# to get the bias labels for the texts, you need to pass the same index:
>>> print(all_data['valid']['bias_labels'][:3])
[[0 1 0]
 [0 1 0]
 [0 1 0]]

# to see the corresponding corpus debiased by human annotators:
>>> print(all_data['valid']['edit_sentence'][:3])
['é‚£æ—¶å€™ä¸œå±±ä¾ç„¶åœ¨ä½¿ç€çœ¼è‰²ï¼Œå¯ä»–çš„æ–°å¨˜å› ä¸ºæ— æ³•ç†è§£è€Œè„¸ä¸Šå¸ƒæ»¡äº†ç–‘æƒ‘ã€‚äºæ˜¯ä¸œå±±ä¾¿å‡‘è¿‡å»å’¬ç‰™åˆ‡é½¿åœ°è¯´äº†ä¸€å¥ä»€ä¹ˆï¼Œæ€»ç®—æ˜ç™½è¿‡æ¥çš„æ–°å¨˜è„¸ä¸Šå‡ºç°äº†å¹½é»˜çš„å¾®ç¬‘ã€‚éšå³ä¸œå±±å’Œä»–çš„æ–°å¨˜ä¸€èµ·ç«™äº†èµ·æ¥ã€‚ä¸œå±±ç«™èµ·æ¥æ—¶ååˆ†é²è½ï¼Œä»–è¸¢å€’äº†æ¤…å­ã€‚æ­£å¦‚æ£®æ—äº‹å…ˆé¢„æ–™çš„ä¸€æ ·ï¼Œä»–ä»¬èµ°è¿›äº†é‚£ä¸ªæˆ¿é—´ã€‚ä½†æ˜¯ä»–ä»¬æ²¡æœ‰å°†é—¨å…³ä¸Šï¼Œæ‰€ä»¥æ£®æ—ä»ç„¶çœ‹åˆ°é‚£å¼ åºŠçš„ä¸€åªè§’ï¼Œä¸è¿‡æ²¡æœ‰çœ‹åˆ°ä»–ä»¬ä¸¤äººï¼Œä»–ä»¬åœ¨åºŠçš„å¦ä¸€ç«¯ã€‚ç„¶åé‚£æ‰‡é—¨å…³ä¸Šäº†ã€‚ä¸ä¹…ä¹‹åï¼Œé‚£é—´å±‹å­é‡Œå‡èµ·äº†ä¸€ç§...'
 'ç³Ÿç³•ä¸œè¥¿ï¼Œå¤§çº¦å¥¹çŸ¥é“è‡ªå·±å¤ªä¸è¡Œï¼Œå¿…é¡»æ‰¾ä¸ªæ¯”å¥¹å†ç³Ÿç³•çš„ã€‚' 'èƒ¡æ–‡ç‰ä¸åªç”Ÿçš„ä¿Šç§€ï¼Œè€Œä¸”å·¥ä½œä¸Šæœ‰é­„åŠ›ï¼Œæœ‰åŠæ³•ï¼Œå†™å¾—ä¸€æ‰‹å¥½æ–‡ç« ï¼Œè®²èµ·è¯æ¥åˆå¤´å¤´æ˜¯é“ã€‚']
```


## æ ‡æ³¨ã€Œæ— åè§ã€çš„è¯­æ–™

æ— åè¯­æ–™åº“ä¹Ÿä»¥ .npy æ ¼å¼å­˜å‚¨ï¼Œä½†æ¯”è¾ƒç®€å•ã€‚å®ƒåªæœ‰ä¸€ä¸ª `text` keyï¼Œå› ä¸ºä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šã€‚æ•°æ®é›†çš„ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
{
    'train':{
        # original corpus
        'text': [
            sent_0,
            sent_1,
            ...,
        ], 
    },
    'valid':{
        ... # similar
    },
    'test':{
        ... # similar
    }
}
```

åŠ è½½æ•°æ®é›†çš„æ–¹æ³•ï¼š

```python
>>> import numpy as np
>>> non_bias_corpus = np.load('dataset/CORGI-PC_splitted_non-bias_corpus_v1.npy',allow_pickle=True).item()
>>> print(non_bias_corpus['valid']['text'][:5])
['å›½ç‹å¿æ‚”äº†ï¼Œä½†æ˜¯ä»–çš„å¤§è‡£ã€å†›é˜Ÿã€äººæ°‘éƒ½å·²ç»éå¸¸å‡¶æ®‹ï¼Œæ— æ³•æ”¹å˜äº†ï¼Œå›½ç‹å°±æƒ³å‡ºä¸€ä¸ªåŠæ³•ã€‚', 
'åŒ—äº¬é˜Ÿçš„æ”»æ‰‹éå¸¸æœ‰å®åŠ›ï¼Œèº«é«˜ã€åŠ›é‡éƒ½å¾ˆå¥½ï¼Œè®­ç»ƒä¸­ä¹Ÿå®‰æ’äº†ç”·æ•™ç»ƒè¿›è¡Œæ¨¡ä»¿ï¼Œåœ¨æ‹¦é˜²ç¯èŠ‚è¦é€‚åº”æ›´å¤šçš„é‡çƒã€‚', 
'å¹´,å¥¹åœ¨æ·˜å®å¼€å‡ºäº†ä¸€å®¶é¹…è‚ä¸“å–åº—ã€‚', 
'è¯¥å…¬å¸è€æ¿è¡¨ç¤º,å½“æ—¶å¥¹æ„Ÿè§‰åˆ°äº†ä¸å¯¹åŠ²,äºæ˜¯å°±ä¸‹æ¥¼æŸ¥çœ‹,æ‰å‘ç°éš”å£è¯åº—ç€ç«äº†ã€‚', 
'é‚£ä¸ªè¾›è‹¦åŠ²å„¿ï¼Œå°±æ˜¯ä¸ªå£®å®çš„ç”·åŠ³åŠ›ä¹Ÿåƒä¸æ¶ˆï¼Œä¸è¿‡æˆ‘ä¹ŸæŒºè¿‡æ¥äº†ï¼']
```

# è‡ªåŠ¨å»é™¤æ–‡æœ¬æ€§åˆ«åè§ç›¸å…³å®éªŒ


## åè§æ£€æµ‹

æˆ‘ä»¬å°†åè§æ£€æµ‹ä»»åŠ¡å®šä¹‰ä¸ºäºŒåˆ†ç±»ä»»åŠ¡ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯ä»¥å¤ç°å®éªŒï¼š

```shell
python -u src/run_classification.py detection 
```

## åè§åˆ†ç±»

æ€§åˆ«åè§ç±»å‹åˆ†ç±»è¢«å®šä¹‰ä¸ºå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤å¤ç°å®éªŒï¼š

```shell
python -u src/run_classification.py detection 
```
## åè§ç¼“è§£

å¾…å®Œæˆ

# å¼•ç”¨

```bibtex
@misc{https://doi.org/10.48550/arxiv.2301.00395,
  doi = {10.48550/ARXIV.2301.00395},
  url = {https://arxiv.org/abs/2301.00395},
  author = {Zhang, Ge and Li, Yizhi and Wu, Yaoyao and Zhang, Linyuan and Lin, Chenghua and Geng, Jiayi and Wang, Shi and Fu, Jie},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
```
